{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "serial-proceeding",
      "metadata": {
        "id": "serial-proceeding"
      },
      "source": [
        "# Experiment 03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "explicit-leather",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "explicit-leather",
        "outputId": "ab5165fd-6311-49b0-f261-fcd9648b7915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "parliamentary-transcript",
      "metadata": {
        "id": "parliamentary-transcript"
      },
      "source": [
        "### Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "centered-aurora",
      "metadata": {
        "id": "centered-aurora"
      },
      "outputs": [],
      "source": [
        "text = 'The general trend in IR systems over time has been from standard use of quite large stop lists (200-300 terms) to very small stop lists (7-12 terms) to no stop list whatsoever. Web search engines generally do not use stop lists.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "configured-brass",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "configured-brass",
        "outputId": "f283e10a-c8f4-4450-dd9b-8434dfc84b8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The general trend in IR systems over time has been from standard use of quite large stop lists (200-300 terms) to very small stop lists (7-12 terms) to no stop list whatsoever. Web search engines generally do not use stop lists.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tamil-technical",
      "metadata": {
        "id": "tamil-technical"
      },
      "source": [
        "### Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "damaged-digit",
      "metadata": {
        "id": "damaged-digit"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK9_DqNEnppo",
        "outputId": "a02b57e9-a438-405e-8bf9-4dc2bd45c9de"
      },
      "id": "YK9_DqNEnppo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "through-symposium",
      "metadata": {
        "id": "through-symposium"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "authentic-answer",
      "metadata": {
        "id": "authentic-answer"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "functional-checkout",
      "metadata": {
        "id": "functional-checkout"
      },
      "source": [
        "#### Applying stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "piano-graph",
      "metadata": {
        "id": "piano-graph"
      },
      "outputs": [],
      "source": [
        "holder = list()\n",
        "for w in words:\n",
        "    if w not in set(stop_words):\n",
        "        holder.append(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accompanied-queens",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "accompanied-queens",
        "outputId": "d752ce97-fb02-4ce8-9a4a-586eb7bb0948"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'general',\n",
              " 'trend',\n",
              " 'IR',\n",
              " 'systems',\n",
              " 'time',\n",
              " 'standard',\n",
              " 'use',\n",
              " 'quite',\n",
              " 'large',\n",
              " 'stop',\n",
              " 'lists',\n",
              " '(',\n",
              " '200-300',\n",
              " 'terms',\n",
              " ')',\n",
              " 'small',\n",
              " 'stop',\n",
              " 'lists',\n",
              " '(',\n",
              " '7-12',\n",
              " 'terms',\n",
              " ')',\n",
              " 'stop',\n",
              " 'list',\n",
              " 'whatsoever',\n",
              " '.',\n",
              " 'Web',\n",
              " 'search',\n",
              " 'engines',\n",
              " 'generally',\n",
              " 'use',\n",
              " 'stop',\n",
              " 'lists',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "holder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "digital-henry",
      "metadata": {
        "id": "digital-henry"
      },
      "source": [
        "#### List Comprehension for stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "environmental-cartridge",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "environmental-cartridge",
        "outputId": "a418a2ae-2e42-4c88-abca-a6d832909a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'general', 'trend', 'IR', 'systems', 'time', 'standard', 'use', 'quite', 'large', 'stop', 'lists', '(', '200-300', 'terms', ')', 'small', 'stop', 'lists', '(', '7-12', 'terms', ')', 'stop', 'list', 'whatsoever', '.', 'Web', 'search', 'engines', 'generally', 'use', 'stop', 'lists', '.']\n"
          ]
        }
      ],
      "source": [
        "holder = [w for w in words if w not in set(stop_words)]\n",
        "print(holder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forty-worth",
      "metadata": {
        "id": "forty-worth"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "related-costs",
      "metadata": {
        "id": "related-costs"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-mobile",
      "metadata": {
        "id": "unsigned-mobile"
      },
      "outputs": [],
      "source": [
        "porter = PorterStemmer()\n",
        "snow = SnowballStemmer(language = 'english')\n",
        "lancaster = LancasterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ready-inside",
      "metadata": {
        "id": "ready-inside"
      },
      "outputs": [],
      "source": [
        "words = ['play', 'plays', 'played', 'playing', 'player']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prostate-commitment",
      "metadata": {
        "id": "prostate-commitment"
      },
      "source": [
        "#### Porter Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "involved-cherry",
      "metadata": {
        "id": "involved-cherry"
      },
      "outputs": [],
      "source": [
        "porter_stemmed = list()\n",
        "for w in words:\n",
        "    stemmed_words = porter.stem(w)\n",
        "    porter_stemmed.append(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "narrative-auditor",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "narrative-auditor",
        "outputId": "ae6f480e-5bdb-4a31-bc48-b765c5844d4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['play', 'play', 'play', 'play', 'player']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "porter_stemmed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mobile-giant",
      "metadata": {
        "id": "mobile-giant"
      },
      "source": [
        "#### Porter Stemmer List Comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "juvenile-assets",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juvenile-assets",
        "outputId": "389086c1-d761-49d2-b6a8-32a254960c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['play', 'play', 'play', 'play', 'player']\n"
          ]
        }
      ],
      "source": [
        "porter_stemmed = [porter.stem(x) for x in words]\n",
        "print (porter_stemmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "japanese-piece",
      "metadata": {
        "id": "japanese-piece"
      },
      "source": [
        "#### Snowball Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skilled-coordinate",
      "metadata": {
        "id": "skilled-coordinate"
      },
      "outputs": [],
      "source": [
        "snow_stemmed = list()\n",
        "for w in words:\n",
        "    stemmed_words = snow.stem(w)\n",
        "    snow_stemmed.append(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "compressed-constitution",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "compressed-constitution",
        "outputId": "b632b9ee-1d96-46e1-de9d-dc8b5fb42bda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['play', 'play', 'play', 'play', 'player']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "snow_stemmed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "handled-preparation",
      "metadata": {
        "id": "handled-preparation"
      },
      "source": [
        "#### Snowball Stemmer List Comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aboriginal-checklist",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aboriginal-checklist",
        "outputId": "b7f474c1-fab3-44ab-a3bd-d66cf432abd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['play', 'play', 'play', 'play', 'player']\n"
          ]
        }
      ],
      "source": [
        "snow_stemmed = [snow.stem(x) for x in words]\n",
        "print (snow_stemmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "narrative-graduation",
      "metadata": {
        "id": "narrative-graduation"
      },
      "source": [
        "#### Lancaster Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gorgeous-omega",
      "metadata": {
        "id": "gorgeous-omega"
      },
      "outputs": [],
      "source": [
        "lancaster_stemmed = list()\n",
        "for w in words:\n",
        "    stemmed_words = lancaster.stem(w)\n",
        "    lancaster_stemmed.append(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "funded-draft",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "funded-draft",
        "outputId": "e31a6f16-eddc-43a1-d6d8-67b8b9f30429"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['play', 'play', 'play', 'play', 'play']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "lancaster_stemmed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stupid-jordan",
      "metadata": {
        "id": "stupid-jordan"
      },
      "source": [
        "#### Lancaster Stemmer List Comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "seven-world",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seven-world",
        "outputId": "ceac8e52-57dd-4cb3-efb1-f5c5750cb37c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['play', 'play', 'play', 'play', 'play']\n"
          ]
        }
      ],
      "source": [
        "lancaster_stemmed = [lancaster.stem(x) for x in words]\n",
        "print (lancaster_stemmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wanted-wallace",
      "metadata": {
        "id": "wanted-wallace"
      },
      "source": [
        "### Lemmatization : This has a more expansive vocabulary than Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "coated-sport",
      "metadata": {
        "id": "coated-sport"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "impressed-switzerland",
      "metadata": {
        "id": "impressed-switzerland"
      },
      "outputs": [],
      "source": [
        "lemmatized = [wordnet.lemmatize(x) for x in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "removed-company",
      "metadata": {
        "id": "removed-company",
        "outputId": "c084cdc5-7def-46a1-ee80-0ffd5f63c7d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['play', 'play', 'played', 'playing', 'player']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "lemmatized"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}